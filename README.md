# CVT Function Library

This library contains functions to generate Centroidal Voronoi points in n-dimensional space. 

## Point Generation

Monte Carlo Points are generated randomly on the unit hypercube according to a given density function. 

```python
   gensample(n, dim=2, density=uniform)
```

```python
   ## srs_sample_test.py ##
   import cvt_processing as cvt
   
   # 2D Example
   uniform_pts  = cvt.srs_pts(100)
   gauss_pts    = cvt.srs_pts(100, 2, cvt.gauss)
   sinusoid_pts = cvt.gensample(100, dim=2, density=cvt.sinusoid)

   # 5D Example
   uniform_pts_5d  = cvt.srs_pts(3, dim=5)
   gauss_pts_5d    = cvt.srs_pts(3, dim=5, density=cvt.gauss)
   sinusoid_pts_5d = cvt.srs_pts(3, 5, cvt.sinusoid)

   ...
```
![Monte Carlo Sample Points](https://github.com/jcs15c/PDE_CVT/blob/master/example_images/srs_sample_fig.png "Monte_Carlo_Sample")
```
   #Text output
   5D Uniform  
   [[-0.97116734 -0.89501887  0.87471317 -0.9724642  -0.0399111 ]
    [ 0.62883577 -0.16562635 -0.60997768  0.47627556  0.23456399]
    [-0.84076283 -0.63156464 -0.11728075  0.57704989  0.14870551]]
   5D Gaussian
   [[ 0.64050097  0.21388999  0.02376145 -0.35474419 -0.07424126]
    [-0.06280193 -0.32578181  0.13600938 -0.16542369 -0.06875906]
    [-0.35886008 -0.18699282  0.1814123   0.22894681 -0.07602129]]
   5D Sinusoidal
   [[ 0.60487684  0.62588684 -0.5362688  -0.56225787 -0.48133396]
    [ 0.53603422  0.36057289 -0.31797064 -0.42140368 -0.34892563]
    [-0.71101366  0.49457508 -0.42284865 -0.42804622 -0.38915426]]
```

While randomly generated points are necessary, they can occasionally "clump," lelading to an uneven distribution. To alleviate this, four other methods of point generation are included, two with random elements and two entirely deterministic. Each method adds a degree of spatial uniformity to the selection of points.

Kmeans++ is a method of Monte Carlo sampling in which each point is randomly selected proportional to the distance between it and the closest point already selected. That is to say, points further away from already selected points are more likely to be selected. The exponent chosen for this distance, with the default being 2, determines by what influence distance has on point selection.

Both the Halton and Hammersley are generated through Halton sequences, in which a prime number is used to generate a pseudo-random sequence of numbers. The nth dimension of a Halton point set is generated by a Halton sequence from the nth prime number. Hammersley points are generated similarly, but require knowing how many points are sampled in total. The first dimension of points is sampled exactly uniformly for its length, subsequent dimensions are generated from subsequent Halton sequences.

Lainized Hypercube points are selected such that each point occupies a particular "row" and "column" in 2D, and can be easily expanded to higher dimensions. This generates a random selection of points, but ensures that the points are not clustered around a particular location. Other point sets can be "latinized" as well, giving them the same "row" and "column" uniqueness while preserving the point set's general shape.
```python 
   kppsample(n, density=uniform, dim=2, alpha=2)
   latin_pts(n, dim=2)
   halton_pts(n, dim=2)
   hammersley_pts(n, dim=2)
```
```python
   ## non_srs_test.py ##
   kpp_pts    = cvt.kpp_pts(100)
   latin_pts  = cvt.latin_pts(100)
   halton_pts = cvt.halton_pts(100)
   hammer_pts = cvt.hammersley_pts(100)

   ...
```
![Non SRS Sample Points](https://github.com/jcs15c/PDE_CVT/blob/master/example_images/non_srs_fig.png "Non_SRS_Sample")

Centroidal Voronoi Tesselations represent another way to evenly distribute points in space. There are two algortihms to generate a CVT: MacQueen's and Lloyd's algorithms.

LLoyd's algorithm involves creating a voronoi tesselation from the existing sample points, where each point is assigned a region of all points in space closer to it than any other sample points. The centroid of each region is then taken to be used as sample points in the next iteration. This process converges relatively quickly, but is very computationally expensive in high dimensions. This is because regions and centroids are calculated with thousands of sample points, which becomes very taxing with more dimensions.

MacQueens algorithm also generates a CVT, but does so by generating a single test point in space, then moving only the sample point closest to it. This results in a slower convergence rate per iteration, but a dramatically faster overall run time in higher dimensions.

The two CVT algorithm functions can be run with respect to a particular density function, and can return an energy calculation, which quantifies the efficiency of the resulting CVT.

```python
   lloyd_step(gens, sample, density=uniform, energy_return=False)
   macqueen_step(gens, js, density=uniform, distance_return=False)
   macqueen_js(n) # Parallel array for MacQueens algorithm
```
```python
   ## cvt_test.py ##

   lloyd_sample = cvt.srs_pts(1000)
   macqueen_js  = cvt.macqueen_js(25)

   # Set up initial points for each algorithm
   init_pts = cvt.srs_pts(25)
   ll_one_it = np.array(init_pts, copy=True)
   mq_one_it = np.array(init_pts, copy=True)

   # Do one iteration of each algorithm
   ll_one_it = cvt.lloyd_step(ll_one_it, lloyd_sample)
   mq_one_it, macqueen_js = cvt.macqueen_step(mq_one_it, macqueen_js)

   # Do 999 more iterations of Macqueens algorithm 
   mq_1000_it = np.array(mq_one_it, copy=True)
   for i in range(999):
      mq_1000_it, macqueen_js = cvt.macqueen_step(mq_1000_it, macqueen_js)

   ## The above routine can be performed with 'cvt_pts(n)' ##
   ...
```

![CVT Sample Points](https://github.com/jcs15c/PDE_CVT/blob/master/example_images/cvt_fig.png "CVT_Sample")

Because latinization is a process which can only be computed on a uniform distribution of points, we require some other way to create a non-uniform distribution. This is done with an inverse transformation into a gaussian distribution, which as seen below has a varied effect for each sample point set.

```
   inverse_transform(pts)  #Converts uniformly sampled points to gaussian distribution.
```

```python
   ## final_test.py ##
   
   n = 50

   srs_pts = cvt.srs_pts(n)
   kpp_pts = cvt.kpp_pts(n)
   hal_pts = cvt.halton_pts(n)
   ham_pts = cvt.hammersley_pts(n)
   lhs_pts = cvt.latin_pts(n)
   cvt_pts = cvt.cvt_pts(n)
   lvt_pts = cvt.cvt_lhs_pts(n)

   ...
```

![Final Test Figure](https://github.com/jcs15c/PDE_CVT/blob/master/example_images/final_fig.png "Final_Figure")
